# Практика 2: Исследование атак на модели ИИ. Fast Gradient Sign Method (FGSM)
Выполнил студент группы ББМО-02-23 Ионов М.С.

## Цель задания:

Познакомиться с одной из популярных атак на системы машинного обучения — атакой Fast Gradient
Sign Method (FGSM). Задача — научиться использовать FGSM для создания противоречивых (adversarial)
примеров, которые могут ввести обученную модель в заблуждение.

Задачи:

  1. Загрузить ранее обученную модель на датасете MNIST.
  2. Изучить теоретические основы FGSM.
  3. Реализовать атаку FGSM и сгенерировать противоречивые примеры.
  4. Оценить точность модели на противоречивых примерах и сравнить с результатами на обычных данных.

